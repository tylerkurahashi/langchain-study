{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "load_dotenv(\"key.env\",verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completions API (Deprecated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tylerkurahashi/Documents/GitHub/langchain_study/venv/lib/python3.8/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "私は、山田太郎と申します。東京都出身で、現在は大学生として都内の大学に通っています。趣味はスポーツ観戦や音楽鑑賞で、特にサッカーやロックバンドが好きです。将来の夢は、国際的な企業で働くことで、留学経験も積んで自分を磨きたいと思っています。また、人とのコミュニケーションを大切にし、常に新しいことに挑戦することで成長していきたいと考えています。よろしくお願いします。\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "\n",
    "\n",
    "result = llm(\"自己紹介してください\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Completions API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AIMessage\n",
    "- HumanMessage\n",
    "- SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "はい、おっしゃった通り、あなたの名前はジョンさんですね。他に何かお手伝いできることがありますか？\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"こんにちは！私はジョンと言います！\"),\n",
    "    AIMessage(content=\"こんにちは、ジョンさん！どのようにお手伝いできますか？\"),\n",
    "    HumanMessage(content=\"私の名前がわかりますか？\")\n",
    "]\n",
    "result = chat(messages)\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming with Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "はじめまして、私はAIアシスタントです。自然言語処理技術を用いて、様々な質問や会話に対応することができます。お手伝いが必要なことがあれば、遠慮なくお知らせください。どうぞよろしくお願いいたします。"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "messages = [HumanMessage(content=\"自己紹介してください\")]\n",
    "result = chat(messages) # type:ignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "以下の料理のレシピを考えてください\n",
      "\n",
      "料理名: カレー\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "以下の料理のレシピを考えてください\n",
    "\n",
    "料理名: {dish}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"dish\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "result = prompt.format(dish=\"カレー\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tylerkurahashi/Documents/GitHub/langchain_study/venv/lib/python3.8/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='あなたはイギリス料理のプロフェッショナルです。', additional_kwargs={}),\n",
      " HumanMessage(content='以下の料理のレシピを考えてください。\\n\\n料理名: 肉じゃが', additional_kwargs={}, example=False)]\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(\"あなたは{country}料理のプロフェッショナルです。\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"以下の料理のレシピを考えてください。\\n\\n料理名: {dish}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_prompt.format_prompt(country=\"イギリス\", dish=\"肉じゃが\").to_messages()\n",
    "pprint(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output parsers\n",
    "LLMの出力からPythonオブジェクトを作成する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    ingredients: List[str] = Field(\n",
    "        description=\"ingredients of the dish\",\n",
    "    )\n",
    "    steps: List[str] = Field(\n",
    "        description=\"steps to make the dish\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The output should be formatted as a JSON instance that conforms to the JSON '\n",
      " 'schema below.\\n'\n",
      " '\\n'\n",
      " 'As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", '\n",
      " '\"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": '\n",
      " '\"string\"}}}, \"required\": [\"foo\"]}\\n'\n",
      " 'the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the '\n",
      " 'schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not '\n",
      " 'well-formatted.\\n'\n",
      " '\\n'\n",
      " 'Here is the output schema:\\n'\n",
      " '```\\n'\n",
      " '{\"properties\": {\"ingredients\": {\"description\": \"ingredients of the dish\", '\n",
      " '\"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, '\n",
      " '\"steps\": {\"description\": \"steps to make the dish\", \"items\": {\"type\": '\n",
      " '\"string\"}, \"title\": \"Steps\", \"type\": \"array\"}}, \"required\": [\"ingredients\", '\n",
      " '\"steps\"]}\\n'\n",
      " '```')\n"
     ]
    }
   ],
   "source": [
    "format_instructions = parser.get_format_instructions()\n",
    "pprint(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "料理のレシピを考えてください\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "料理名: {dish}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"dish\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n'\n",
      " '料理のレシピを考えてください\\n'\n",
      " '\\n'\n",
      " 'The output should be formatted as a JSON instance that conforms to the JSON '\n",
      " 'schema below.\\n'\n",
      " '\\n'\n",
      " 'As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", '\n",
      " '\"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": '\n",
      " '\"string\"}}}, \"required\": [\"foo\"]}\\n'\n",
      " 'the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the '\n",
      " 'schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not '\n",
      " 'well-formatted.\\n'\n",
      " '\\n'\n",
      " 'Here is the output schema:\\n'\n",
      " '```\\n'\n",
      " '{\"properties\": {\"ingredients\": {\"description\": \"ingredients of the dish\", '\n",
      " '\"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, '\n",
      " '\"steps\": {\"description\": \"steps to make the dish\", \"items\": {\"type\": '\n",
      " '\"string\"}, \"title\": \"Steps\", \"type\": \"array\"}}, \"required\": [\"ingredients\", '\n",
      " '\"steps\"]}\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " '料理名: カレー\\n')\n"
     ]
    }
   ],
   "source": [
    "formatted_prompt = prompt.format(dish=\"カレー\")\n",
    "pprint(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('```json\\n'\n",
      " '{\\n'\n",
      " '    \"ingredients\": [\\n'\n",
      " '        \"玉ねぎ\",\\n'\n",
      " '        \"人参\",\\n'\n",
      " '        \"じゃがいも\",\\n'\n",
      " '        \"牛肉\",\\n'\n",
      " '        \"カレールー\",\\n'\n",
      " '        \"水\"\\n'\n",
      " '    ],\\n'\n",
      " '    \"steps\": [\\n'\n",
      " '        \"1. 材料を準備する。\",\\n'\n",
      " '        \"2. 玉ねぎ、人参、じゃがいもを切る。\",\\n'\n",
      " '        \"3. 牛肉を炒める。\",\\n'\n",
      " '        \"4. 野菜を加えて炒める。\",\\n'\n",
      " '        \"5. 水を加えて煮込む。\",\\n'\n",
      " '        \"6. カレールーを溶かして加える。\",\\n'\n",
      " '        \"7. 全体を混ぜて完成。\"\\n'\n",
      " '    ]\\n'\n",
      " '}\\n'\n",
      " '```')\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "messages = [HumanMessage(content=formatted_prompt)]\n",
    "output = chat(messages)\n",
    "pprint(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Recipe'>\n",
      "Recipe(ingredients=['玉ねぎ', '人参', 'じゃがいも', '牛肉', 'カレールー', '水'], steps=['1. 材料を準備する。', '2. 玉ねぎ、人参、じゃがいもを切る。', '3. 牛肉を炒める。', '4. 野菜を加えて炒める。', '5. 水を加えて煮込む。', '6. カレールーを溶かして加える。', '7. 全体を混ぜて完成。'])\n"
     ]
    }
   ],
   "source": [
    "recipe = parser.parse(output.content)\n",
    "print(type(recipe))\n",
    "pprint(recipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    ingredients: List[str] = Field(description=\"ingredients of the dish\")\n",
    "    steps: List[str] = Field(description=\"steps to make the dish\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Recipe)\n",
    "\n",
    "template = \"\"\"\n",
    "料理のレシピを考えてください\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "料理名: {dish}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"dish\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Recipe'>\n",
      "Recipe(ingredients=['玉ねぎ', '人参', 'じゃがいも', '牛肉', 'カレールー', '水'], steps=['1. 材料を準備する。', '2. 玉ねぎ、人参、じゃがいもを切る。', '3. 牛肉を炒める。', '4. 野菜を加えて炒める。', '5. 水を加えて煮込む。', '6. カレールーを溶かして加える。', '7. 全体を混ぜて完成。'])\n"
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "\n",
    "chain = LLMChain(prompt=prompt, llm=chat, output_parser=output_parser)\n",
    "\n",
    "recipe = chain.run(dish=\"カレー\")\n",
    "print(type(recipe))\n",
    "pprint(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "cot_template = \"\"\"\n",
    "以下の質問に回答してください\n",
    "\n",
    "質問: {question}\n",
    "\n",
    "ステップバイステップで考えましょう。\n",
    "\"\"\"\n",
    "\n",
    "cot_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=cot_template,\n",
    ")\n",
    "\n",
    "cot_chain = LLMChain(llm=chat, prompt=cot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_template = \"\"\"\n",
    "以下の文章を結論だけ一言に要約してください\n",
    "\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "summarize_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    template=summarize_template\n",
    ")\n",
    "\n",
    "summarize_chain = LLMChain(llm=chat, prompt=summarize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "残りのりんごは10個。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "cot_summarize_chain = SimpleSequentialChain(\n",
    "    chains=[cot_chain, summarize_chain],\n",
    ")\n",
    "\n",
    "result = cot_summarize_chain(\n",
    "    \"私は市場に行って10個のりんごを買いました。隣人に2つ、修理工に2つ渡しました。それから5つのりんごを買って1つ食べました。残りは何個ですか？\"\n",
    ")\n",
    "\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: こんにちは、Tylerさん。私はAIです。どのようにお手伝いできますか？\n",
      "AI: はい、Tylerさんの名前を知っています。それはあなたの自己紹介で教えてくれたからです。他に何か知りたいことがありますか？\n",
      "AI: 何か質問があれば遠慮なくどうぞ。私はできる限りお手伝いします。\n",
      "AI:  了解しました。もし何か他の質問やお手伝いが必要な場合はいつでもお知らせくださいね。良い一日を！\n",
      "AI:  それでは、またお会いしましょう。良い一日を！\n",
      "AI:  さようなら！またお会いしましょう。\n",
      "AI:  さようなら！またお会いしましょう。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=ConversationBufferMemory()\n",
    ")\n",
    "\n",
    "while True: # -> infinite loop\n",
    "    user_message = input(\"You: \")\n",
    "    ai_message = conversation.run(input=user_message)\n",
    "    print(f\"AI: {ai_message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
